{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X=data.data\n",
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=data.target_names\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 50]\n",
      " [ 1 50]\n",
      " [ 2 50]]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 1, 2,\n",
       "       0, 1, 1, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross validation:\n",
      "\n",
      "Accuracy: 0.97 (+/- 0.04) [KNN]\n",
      "Accuracy: 0.97 (+/- 0.04) [Random Forest]\n",
      "Accuracy: 0.97 (+/- 0.04) [Naive Bayes]\n",
      "Accuracy: 0.97 (+/- 0.04) [StackingClassifier]\n",
      "Accuracy: 0.97 (+/- 0.04) [XGB]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
    "                          meta_classifier=lr)\n",
    "xg=XGBClassifier()\n",
    "\n",
    "print('3-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, sclf,xg], \n",
    "                      ['KNN', \n",
    "                       'Random Forest', \n",
    "                       'Naive Bayes',\n",
    "                       'StackingClassifier','XGB']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X_train, Y_train, \n",
    "                                              cv=10, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_Model=SVC(probability=True)\n",
    "SVC_Model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98333 (+/- 0.03) [['setosa' 'versicolor' 'virginica']]\n"
     ]
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(SVC_Model, X_train, Y_train,cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.2f) [%s]\"% (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916666666666667"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_Model.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 2, 1, 0, 2, 0, 1, 1, 2, 2, 2, 0, 0, 2, 2, 0, 0, 1, 2,\n",
       "       0, 1, 1, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=SVC_Model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 2, 1, 0, 1, 0, 1, 1, 2, 2, 2, 0, 0, 2, 2, 0, 0, 1, 2,\n",
       "       0, 1, 1, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(SVC_Model.predict_proba(X_test),axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['versicolor', 'virginica', 'virginica', 'setosa', 'virginica',\n",
       "       'versicolor', 'setosa', 'virginica', 'setosa', 'versicolor',\n",
       "       'versicolor', 'virginica', 'virginica', 'virginica', 'setosa',\n",
       "       'setosa', 'virginica', 'virginica', 'setosa', 'setosa',\n",
       "       'versicolor', 'virginica', 'setosa', 'versicolor', 'versicolor',\n",
       "       'virginica', 'versicolor', 'versicolor', 'versicolor', 'virginica'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.9881527 ],\n",
       "       [2.        , 0.91689922],\n",
       "       [2.        , 0.98238323],\n",
       "       [0.        , 0.95793752],\n",
       "       [2.        , 0.97832003],\n",
       "       [1.        , 0.93894438],\n",
       "       [0.        , 0.96334502],\n",
       "       [2.        , 0.6218673 ],\n",
       "       [0.        , 0.9550199 ],\n",
       "       [1.        , 0.80309687],\n",
       "       [1.        , 0.87188701],\n",
       "       [2.        , 0.5149602 ],\n",
       "       [2.        , 0.98285678],\n",
       "       [2.        , 0.97533079],\n",
       "       [0.        , 0.95959   ],\n",
       "       [0.        , 0.94762669],\n",
       "       [2.        , 0.68608218],\n",
       "       [2.        , 0.97411038],\n",
       "       [0.        , 0.96349614],\n",
       "       [0.        , 0.96329281],\n",
       "       [1.        , 0.98824707],\n",
       "       [2.        , 0.98476615],\n",
       "       [0.        , 0.96377361],\n",
       "       [1.        , 0.68838391],\n",
       "       [1.        , 0.97983364],\n",
       "       [2.        , 0.97915861],\n",
       "       [1.        , 0.9857628 ],\n",
       "       [1.        , 0.98020211],\n",
       "       [1.        , 0.92273486],\n",
       "       [2.        , 0.98546714]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([pred.reshape(-1,1),np.max(SVC_Model.predict_proba(X_test),axis=1).reshape(-1,1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0013333956400553386\n",
      "fit_time  std  0.0018857061981754134\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  0.9500000000000001\n",
      "test_score  std  0.035355339059327355\n",
      "train_score  mean  0.9583333333333334\n",
      "train_score  std  0.005892556509887928\n",
      "---------------------------------\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0040005842844645185\n",
      "fit_time  std  1.5734823444067107e-06\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  0.9833333333333334\n",
      "test_score  std  0.011785113019775804\n",
      "train_score  mean  0.9833333333333334\n",
      "train_score  std  0.005892556509887928\n",
      "---------------------------------\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0\n",
      "fit_time  std  0.0\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  0.9833333333333334\n",
      "test_score  std  0.011785113019775804\n",
      "train_score  mean  0.9833333333333334\n",
      "train_score  std  0.005892556509887928\n",
      "---------------------------------\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0013333956400553386\n",
      "fit_time  std  0.0018857061981754136\n",
      "score_time  mean  0.0013335545857747395\n",
      "score_time  std  0.0018859309813674717\n",
      "test_score  mean  0.9666666666666667\n",
      "test_score  std  0.011785113019775802\n",
      "train_score  mean  0.9791666666666666\n",
      "train_score  std  0.021245914639969964\n",
      "---------------------------------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "-----------------------------------\n",
      "fit_time  mean  0.0\n",
      "fit_time  std  0.0\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  0.9666666666666667\n",
      "test_score  std  0.023570226039551608\n",
      "train_score  mean  1.0\n",
      "train_score  std  0.0\n",
      "---------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "-----------------------------------\n",
      "fit_time  mean  0.013177871704101562\n",
      "fit_time  std  0.009912315596117143\n",
      "score_time  mean  0.0\n",
      "score_time  std  0.0\n",
      "test_score  mean  0.9583333333333334\n",
      "test_score  std  0.03118047822311617\n",
      "train_score  mean  1.0\n",
      "train_score  std  0.0\n",
      "---------------------------------\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "-----------------------------------\n",
      "fit_time  mean  0.14041709899902344\n",
      "fit_time  std  0.01582241911349771\n",
      "score_time  mean  0.0013306140899658203\n",
      "score_time  std  0.0018817724923143968\n",
      "test_score  mean  0.9583333333333334\n",
      "test_score  std  0.03118047822311617\n",
      "train_score  mean  1.0\n",
      "train_score  std  0.0\n",
      "---------------------------------\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "       colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "       gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "       learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "       min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "       n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "       objective='binary:logistic', random_state=None, reg_alpha=None,\n",
      "       reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "       tree_method=None, validate_parameters=False, verbosity=None)\n",
      "-----------------------------------\n",
      "fit_time  mean  0.053124030431111656\n",
      "fit_time  std  0.008889153553975656\n",
      "score_time  mean  0.004008372624715169\n",
      "score_time  std  0.003275681406025348\n",
      "test_score  mean  0.9583333333333334\n",
      "test_score  std  0.03118047822311617\n",
      "train_score  mean  1.0\n",
      "train_score  std  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "clfs = []\n",
    "clfs.append(LogisticRegression())\n",
    "clfs.append(SVC(probability=True))\n",
    "clfs.append(SVC())\n",
    "clfs.append(KNeighborsClassifier(n_neighbors=3))\n",
    "clfs.append(DecisionTreeClassifier())\n",
    "clfs.append(RandomForestClassifier())\n",
    "clfs.append(GradientBoostingClassifier())\n",
    "clfs.append(XGBClassifier())\n",
    "\n",
    "\n",
    "for classifier in clfs:\n",
    "    scores = cross_validate(classifier, X_train, Y_train)\n",
    "    print('---------------------------------')\n",
    "    print(str(classifier))\n",
    "    print('-----------------------------------')\n",
    "    for key, values in scores.items():\n",
    "            print(key,' mean ', values.mean())\n",
    "            print(key,' std ', values.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_Model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
