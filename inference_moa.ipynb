{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from joblib import dump, load\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 128\n",
    "NFOLDS = 5\n",
    "hidden_size=1400\n",
    "data_dir = 'D:\\\\Dataset\\\\MOA\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(train_file, test_file, target_file, path=data_dir):\n",
    "    \n",
    "    df_train=pd.read_csv(os.path.join(path, train_file))\n",
    "    df_test=pd.read_csv(os.path.join(path, test_file))\n",
    "    df_target=pd.read_csv(os.path.join(path, target_file))\n",
    "    \n",
    "    print(df_train.shape, df_test.shape, df_target.shape, df_test.shape)\n",
    "    \n",
    "    return df_train, df_test, df_target, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 876) (3982, 876) (23814, 207) (3982, 876)\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features, train_targets_scored, test_final = read_data('train_features.csv', 'test_features.csv', 'train_targets_scored.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENES\n",
    "n_comp = 100\n",
    "\n",
    "cells_genes = load('std_scaler_genes.bin')\n",
    "\n",
    "test2 = cells_genes.transform(test_features[GENES])\n",
    "\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 15\n",
    "\n",
    "cells_pca = load('std_scaler_cells.bin')\n",
    "\n",
    "\n",
    "test2 = cells_pca.transform(test_features[CELLS])\n",
    "\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "variance = load('Variance_transform.bin')\n",
    "\n",
    "data_transformed = variance.transform(test_features.iloc[:, 4:])\n",
    "\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                            columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(data_transformed)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = load('target_cols.bin')\n",
    "feature_cols = load('feature_cols.bin')\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "982"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "\n",
    "    def __init__(self, sigma=0.5, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.register_buffer('noise', torch.tensor(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.expand(*x.size()).float().normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size, dropout):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dense1 = nn.Linear(num_features, hidden_size)\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dense2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.dense3 = nn.Linear(hidden_size, num_targets)\n",
    "        #bias_ = torch.Tensor(bias)\n",
    "        #print(self.dense3.bias.data)\n",
    "        #nn.init.xavier_normal_(self.dense3.weight)\n",
    "        #self.dense3.bias = torch.nn.Parameter(_bias)\n",
    "        self.gausian = GaussianNoise()\n",
    "        #self.relu=nn.PReLU()\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        #x = self.gausian(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.gausian(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(fold, seed):\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    test_ = process_data(test)\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features = num_features,\n",
    "        num_targets = num_targets,\n",
    "        hidden_size = 1400,\n",
    "        dropout = 0.10721077648722396\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"C:\\\\Users\\\\acer\\\\5foldbest_model_{fold}_{seed}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), train_targets_scored.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        pred_ = run_inference(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 5\n",
    "SEED = [0, 1, 2, 3, 4, 5]\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "    \n",
    "for i in target_cols:\n",
    "    test[i]=0.\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3624, 206)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.zeros((len(test), len(target_cols)))\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = np.load('model_01840.npy')\n",
    "predictions2 = np.load('MoA_Model_01844.npy')\n",
    "predictions3 = np.load('MoA_Model_01858.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3624, 206)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[target_cols] = (predictions1 + predictions2 + predictions3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(data_dir+'sample_submission.csv')\n",
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub[target_cols] = sub[target_cols]\n",
    "sub.to_csv('submission_04_11_2020_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.003245</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>0.019685</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.007545</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.012881</td>\n",
       "      <td>0.001739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.002642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.011902</td>\n",
       "      <td>0.016398</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.014083</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.002613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.017793</td>\n",
       "      <td>0.018539</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.002238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.171051</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.010698</td>\n",
       "      <td>0.022298</td>\n",
       "      <td>0.007703</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.002124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.033735</td>\n",
       "      <td>0.006725</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.001291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.024451</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.003338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>0.018656</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.001067                0.001489   \n",
       "1     id_001897cda                     0.000642                0.001008   \n",
       "2     id_002429b5b                     0.000000                0.000000   \n",
       "3     id_00276f245                     0.001167                0.001284   \n",
       "4     id_0027f1083                     0.001768                0.001930   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.000834                0.001181   \n",
       "3978  id_ff925dd0d                     0.002922                0.002213   \n",
       "3979  id_ffb710450                     0.001488                0.001273   \n",
       "3980  id_ffbb869f2                     0.002003                0.001525   \n",
       "3981  id_ffd5800b6                     0.000839                0.001273   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.003245                        0.014741   \n",
       "1           0.002189                        0.002892   \n",
       "2           0.000000                        0.000000   \n",
       "3           0.002189                        0.011902   \n",
       "4           0.002055                        0.017793   \n",
       "...              ...                             ...   \n",
       "3977        0.001048                        0.001909   \n",
       "3978        0.001309                        0.010698   \n",
       "3979        0.001212                        0.012353   \n",
       "3980        0.001547                        0.024451   \n",
       "3981        0.001388                        0.011644   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.019685                        0.005112   \n",
       "1                              0.001563                        0.002115   \n",
       "2                              0.000000                        0.000000   \n",
       "3                              0.016398                        0.005296   \n",
       "4                              0.018539                        0.004153   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.006710                        0.002374   \n",
       "3978                           0.022298                        0.007703   \n",
       "3979                           0.033735                        0.006725   \n",
       "3980                           0.028090                        0.006004   \n",
       "3981                           0.018656                        0.004914   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.002076                       0.007545   \n",
       "1                       0.004489                       0.010103   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       0.003828                       0.004723   \n",
       "4                       0.005446                       0.002343   \n",
       "...                          ...                            ...   \n",
       "3977                    0.000743                       0.002414   \n",
       "3978                    0.006419                       0.005270   \n",
       "3979                    0.002481                       0.004792   \n",
       "3980                    0.006469                       0.003622   \n",
       "3981                    0.002005                       0.003384   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.000410  ...                               0.001131   \n",
       "1                       0.005707  ...                               0.001091   \n",
       "2                       0.000000  ...                               0.000000   \n",
       "3                       0.000474  ...                               0.000890   \n",
       "4                       0.000703  ...                               0.001164   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.000310  ...                               0.000530   \n",
       "3978                    0.001092  ...                               0.000811   \n",
       "3979                    0.000278  ...                               0.000678   \n",
       "3980                    0.000668  ...                               0.000922   \n",
       "3981                    0.000331  ...                               0.000764   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.002354         0.005651           0.001514   \n",
       "1         0.001199         0.005310           0.000446   \n",
       "2         0.000000         0.000000           0.000000   \n",
       "3         0.001514         0.003017           0.014083   \n",
       "4         0.000817         0.003894           0.001481   \n",
       "...            ...              ...                ...   \n",
       "3977      0.004438         0.001619           0.171051   \n",
       "3978      0.001140         0.003834           0.002317   \n",
       "3979      0.000745         0.002816           0.002256   \n",
       "3980      0.000614         0.002713           0.001172   \n",
       "3981      0.001388         0.002090           0.005076   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.000914                               0.000893   \n",
       "1                      0.008168                               0.000693   \n",
       "2                      0.000000                               0.000000   \n",
       "3                      0.006298                               0.000926   \n",
       "4                      0.001626                               0.001054   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.006616                               0.000860   \n",
       "3978                   0.002932                               0.000901   \n",
       "3979                   0.001568                               0.000672   \n",
       "3980                   0.002303                               0.000744   \n",
       "3981                   0.001533                               0.000869   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.000935   0.002105                    0.012881       0.001739  \n",
       "1            0.006653   0.001270                    0.001200       0.002642  \n",
       "2            0.000000   0.000000                    0.000000       0.000000  \n",
       "3            0.002061   0.002405                    0.000620       0.002613  \n",
       "4            0.001665   0.002277                    0.000343       0.002238  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.006085   0.001164                    0.000538       0.000788  \n",
       "3978         0.001969   0.001946                    0.000564       0.002124  \n",
       "3979         0.001146   0.001618                    0.000601       0.001291  \n",
       "3980         0.001500   0.002301                    0.000509       0.003338  \n",
       "3981         0.000973   0.002105                    0.000440       0.001407  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('submission_04_11_2020_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>0.019372</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>0.001377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.013349</td>\n",
       "      <td>0.005101</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.001848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.011650</td>\n",
       "      <td>0.017050</td>\n",
       "      <td>0.005956</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.010345</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.002970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.021457</td>\n",
       "      <td>0.023154</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.007014</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.013337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.017093</td>\n",
       "      <td>0.020522</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.016768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.173384</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3620</th>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.001558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3621</th>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.013465</td>\n",
       "      <td>0.035332</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.011860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.001228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622</th>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.021896</td>\n",
       "      <td>0.032116</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>0.023989</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.008837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.001404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3624 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n",
       "0                        0.000601                0.000580        0.002132   \n",
       "1                        0.000316                0.000408        0.001128   \n",
       "2                        0.001089                0.000915        0.001431   \n",
       "3                        0.001757                0.001432        0.002156   \n",
       "4                        0.000832                0.000563        0.002095   \n",
       "...                           ...                     ...             ...   \n",
       "3619                     0.000582                0.000647        0.000516   \n",
       "3620                     0.002929                0.002572        0.000990   \n",
       "3621                     0.001383                0.000937        0.000854   \n",
       "3622                     0.001825                0.001273        0.001146   \n",
       "3623                     0.000923                0.001151        0.001229   \n",
       "\n",
       "      acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n",
       "0                           0.014111                           0.019372   \n",
       "1                           0.000984                           0.001354   \n",
       "2                           0.011650                           0.017050   \n",
       "3                           0.021457                           0.023154   \n",
       "4                           0.017093                           0.020522   \n",
       "...                              ...                                ...   \n",
       "3619                        0.002353                           0.006627   \n",
       "3620                        0.011168                           0.023285   \n",
       "3621                        0.013465                           0.035332   \n",
       "3622                        0.021896                           0.032116   \n",
       "3623                        0.011399                           0.023989   \n",
       "\n",
       "      acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "0                           0.004123                    0.001981   \n",
       "1                           0.001008                    0.002878   \n",
       "2                           0.005956                    0.003185   \n",
       "3                           0.004425                    0.007014   \n",
       "4                           0.003890                    0.005721   \n",
       "...                              ...                         ...   \n",
       "3619                        0.001886                    0.000435   \n",
       "3620                        0.007199                    0.005775   \n",
       "3621                        0.005973                    0.003065   \n",
       "3622                        0.005774                    0.004900   \n",
       "3623                        0.005517                    0.002420   \n",
       "\n",
       "      adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "0                          0.004428                    0.000180   \n",
       "1                          0.013349                    0.005101   \n",
       "2                          0.004950                    0.000278   \n",
       "3                          0.002649                    0.000438   \n",
       "4                          0.001667                    0.000407   \n",
       "...                             ...                         ...   \n",
       "3619                       0.001814                    0.000201   \n",
       "3620                       0.004192                    0.000486   \n",
       "3621                       0.003157                    0.000159   \n",
       "3622                       0.004232                    0.000292   \n",
       "3623                       0.003170                    0.000193   \n",
       "\n",
       "      adrenergic_receptor_agonist  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                        0.012393  ...                               0.000829   \n",
       "1                        0.003829  ...                               0.000565   \n",
       "2                        0.010074  ...                               0.000621   \n",
       "3                        0.013337  ...                               0.000919   \n",
       "4                        0.016768  ...                               0.000814   \n",
       "...                           ...  ...                                    ...   \n",
       "3619                     0.003199  ...                               0.000284   \n",
       "3620                     0.013829  ...                               0.000614   \n",
       "3621                     0.011860  ...                               0.000385   \n",
       "3622                     0.015667  ...                               0.000541   \n",
       "3623                     0.008837  ...                               0.000573   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.001340         0.003232           0.001830   \n",
       "1         0.000343         0.004205           0.000170   \n",
       "2         0.000886         0.002419           0.010345   \n",
       "3         0.000616         0.004727           0.001542   \n",
       "4         0.000619         0.004106           0.001329   \n",
       "...            ...              ...                ...   \n",
       "3619      0.001867         0.001109           0.173384   \n",
       "3620      0.000678         0.004173           0.002656   \n",
       "3621      0.000493         0.002019           0.001526   \n",
       "3622      0.000439         0.003301           0.001051   \n",
       "3623      0.000821         0.001816           0.004267   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.000871                               0.000555   \n",
       "1                      0.008188                               0.000308   \n",
       "2                      0.005757                               0.000644   \n",
       "3                      0.001235                               0.000846   \n",
       "4                      0.001049                               0.000487   \n",
       "...                         ...                                    ...   \n",
       "3619                   0.006523                               0.000580   \n",
       "3620                   0.001945                               0.001026   \n",
       "3621                   0.001354                               0.000481   \n",
       "3622                   0.002008                               0.000628   \n",
       "3623                   0.001577                               0.000715   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.001077   0.001612                    0.009336       0.001377  \n",
       "1            0.010038   0.000603                    0.000206       0.001848  \n",
       "2            0.001493   0.002048                    0.000887       0.002970  \n",
       "3            0.001258   0.002104                    0.000423       0.002304  \n",
       "4            0.000345   0.002103                    0.000192       0.001450  \n",
       "...               ...        ...                         ...            ...  \n",
       "3619         0.004224   0.000901                    0.000295       0.000629  \n",
       "3620         0.002470   0.001675                    0.000373       0.001558  \n",
       "3621         0.000658   0.001150                    0.000337       0.001228  \n",
       "3622         0.002060   0.001620                    0.000622       0.002700  \n",
       "3623         0.000877   0.001666                    0.000475       0.001404  \n",
       "\n",
       "[3624 rows x 206 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[target_cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
